{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Probabilistic Graphical Models\n",
    "## Practical Session 2\n",
    "### Author: Xiang Yu, Email: shawnxiangyu@yahoo.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from scipy.linalg import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pyparsing\n",
    "from IPython.display import Math\n",
    "import copy\n",
    "import math\n",
    "from matplotlib.patches import Ellipse \n",
    "## we first run the code with the warning enabled, if no error of relevant warning is to be found, \n",
    "## we disable the warning then\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "math_pi = math.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a large font size by default and use tex for math\n",
    "fontsize = 18\n",
    "params = {'axes.labelsize': fontsize + 2,\n",
    "      'font.size': fontsize + 2,\n",
    "      'legend.fontsize': fontsize + 2,\n",
    "      'xtick.labelsize': fontsize,\n",
    "      'ytick.labelsize': fontsize,\n",
    "      'text.usetex': True}\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to compute    \n",
    "$$\n",
    "\\large \\gamma_i(x) = \\frac{\\pi_i \\mathcal{N}(x;\\mu_i, \\Sigma_i)}{ \\sum_{j=1}^K \\pi_j \\mathcal{N}(x;\\mu_j, \\Sigma_j)}\n",
    "$$\n",
    "We define $g_i(x) = \\pi_i \\mathcal{N}(x;\\mu_i, \\Sigma_i)$ and $lg_i = \\log g_i(x)$, then the log of the nominator is equal to: \n",
    "\n",
    "\\begin{align}\n",
    "\\large \\log g_i(x) \n",
    "& \\large = \\log \\left(\\pi_i \\mathcal{N}(x;\\mu_i, \\Sigma_i) \\right)\\\\\n",
    "& \\large = \\log \\left( \\pi_i \\frac{1}{(2 \\pi)^{K/2} |\\Sigma_i|^{1/2}} \\exp \\left(-\\frac{1}{2}(x-\\mu_i)^T \\Sigma_i^{-1}(x-\\mu_i)\\right)\\right)\\\\\n",
    "& \\large = \\log \\pi_i - \\frac{1}{2} \\left( K \\log (2 \\pi) + \\log |\\Sigma_i|\\right) - \\frac{1}{2}(x-\\mu_i)^T \\Sigma_i^{-1}(x-\\mu_i)\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we could compute $gamma_i(x)$ as follows: \n",
    "\n",
    "\\begin{align}\n",
    "\\large \\gamma_i(x) &=  \\large \\frac{\\pi_i \\mathcal{N}(x;\\mu_i, \\Sigma_i)}{ \\sum_{j=1}^K \\pi_j \\mathcal{N}(x;\\mu_j, \\Sigma_j)} \\\\\n",
    "& \\large = \\frac {g_i(x)}{\\sum_{j=1}^K g_j(x)} = \\frac {\\exp(\\log(g_i(x)))}{\\sum_{j=1}^K \\exp(\\log(g_j(x)))} \\\\\n",
    "&  \\large =  \\frac{\\exp(lg_i- maxlg)\\exp(maxlg)}{\\sum_{j=1}^K \\exp(lg_j-maxlg) \\exp(maxlg)} \\\\\n",
    "&  \\large =  \\frac{\\exp(lg_i-maxlg)}{\\sum_{j=1}^K \\exp(lg_j-maxlg)}\n",
    "\\end{align}\n",
    "where $ maxlg = \\max_j lg_j =\\max_j \\log g_j(x), j = 1, ..., K$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From lecture notes, we have: \n",
    "$$\n",
    "\\large \\mathcal{L}_t(\\theta) =  \\sum_{n=1}^N \\sum_{k=1}^K  \\gamma_k^{(t)} (x_n) \\log \\mathcal{N}(x_n;\\mu_k, \\Sigma_k) + \\sum_{n=1}^N \\sum_{k=1}^K  \\gamma_k^{(t)} (x_n) \\log \\pi_k\\\\\n",
    "$$\n",
    "\n",
    "$\\mathcal{M}$-step \n",
    "\n",
    "\\begin{equation*}\n",
    "\\large \\theta^{(t+1)} = \\arg \\max_\\theta \\mathcal{L}_t(\\theta) \n",
    "\\end{equation*}\n",
    "where $\\theta^{(t)} = (\\mu_k^{(t)}, \\Sigma_k^{(t)}, \\pi_k^{(t)})$\n",
    "\n",
    "\n",
    "For $\\mu_k^{(t+1)}$: \n",
    "\n",
    "\\begin{align}\n",
    "\\large \\frac{\\partial \\mathcal{L}_t(\\theta) }{\\partial \\mu_k^*}  \\propto \\sum_{n=1}^N \\gamma_k^{(t)} (\\Sigma_k)^{-1}(x_n-\\mu_k^*) = 0 \n",
    "& \\large \\  : \\  \\sum_{n=1}^N \\gamma_k^{(t)}(x_n) (\\Sigma_k)^{-1}(x_n-\\mu_k^*) = 0  \\\\\n",
    "& \\large  \\sum_{n=1}^N \\gamma_k^{(t)}(x_n) (\\Sigma_k)^{-1} x_n =  \\sum_{n=1}^N \\gamma_k^{(t)} (\\Sigma_k)^{-1}\\mu_k^*  \\\\\n",
    "& \\large   \\mu^*(: = \\mu_k^{(t+1)}) = \\frac{\\sum_{n=1}^N \\gamma_k^{(t)}(x_n). x_n}{\\sum_{n=1}^N \\gamma_k^{(t)}(x_n)}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $\\pi_k^{(t+1)}$\n",
    "\n",
    "We rewirte the formula for\n",
    "\\begin{align*}\n",
    "\\large \\mathcal{L}_t(\\theta)  \n",
    "& \\large = \\sum_{n=1}^N \\sum_{k=1}^K \\gamma_k^{(t)} (x_n) \\log \\left( \\pi_k \\mathcal{N}(x_n;\\mu_k, \\Sigma_k) \\right)  \\\\\n",
    "& \\large =  \\sum_{n=1}^N \\sum_{k=1}^K \\gamma_k^{(t)} (x_n) l_k(x_n)  \\\\\n",
    "&  \\large= \\sum_{n=1}^N \\sum_{k=1}^K \\gamma_k^{(t)} (x_n) \\left( \\log \\pi_k - \\frac{1}{2} \\left( K \\log (2 \\pi) + \\log |\\Sigma_k|\\right) - \\frac{1}{2}(x-\\mu_k)^T \\Sigma_k^{-1}(x-\\mu_i))\\right)\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align}\n",
    "\\large \\frac{\\partial \\mathcal{L}_t(\\theta) }{\\partial \\pi_k^*} = 0 \n",
    "& \\large \\  : \\  \\sum_{n=1}^N \\sum_{k=1}^K \\gamma_k^{(t)}(x_n) \\frac{1}{\\pi_k^*}= 0  \\\\\n",
    "\\end{align}\n",
    "\n",
    "Together With $\\sum_{k=1}^K \\pi_k^*=1$, we get: \n",
    "$$ \\large \\pi_k^* (:\\pi_k^{(t+1)}) = \\frac{1}{N}\\sum_{n=1}^N \\gamma_k^{(t)} (x_n) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For  $\\Sigma_k^{(t+1)}$: \n",
    "\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "\\large \\frac{\\partial \\mathcal{L}_t(\\theta) }{\\partial \\Sigma_k^*} = 0  \n",
    " \\large \\ : \\  \\propto \\   \\sum_{n=1}^N \\gamma_k^{(t)} (x_n) \\left( - (\\Sigma_k^*) + (x-\\mu_k) (x-\\mu_k)^T \\right) &= 0 \\\\\n",
    " \\large\\sum_{n=1}^N \\gamma_k^{(t)} (x_n) \\Sigma_k^* & = \\sum_{n=1}^N \\gamma_k^{(t)} (x_n) \\left((x-\\mu_k) (x-\\mu_k)^T \\right)\\\\\n",
    "\\large  \\Sigma_k^* (: = \\Sigma_k^{t+1}) & = \\frac{\\sum_{n=1}^N \\gamma_k^{(t) } (x_n)(x-\\mu_k) (x-\\mu_k)^T}{\\sum_{n=1}^N \\gamma_k^{(t)} (x_n)} \n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "\n",
    "K = 3\n",
    "colors = ['b', 'r', 'k']\n",
    "pi = np.array([0.3, 0.2, 0.5])\n",
    "us = np.array([[0, 0], [1, 2], [2,0]])\n",
    "\n",
    "# sg1 = np.array([[1, -0.25], [-0.25, 0.5]])\n",
    "# sg2 = np.array([[0.5, 0.25],[0.25, 0.5]])\n",
    "# sg3 = np.array([[0.5, -0.25],[-0.25, 1]])\n",
    "# sigmas = [sg1, sg2, sg3]\n",
    "sgs = np.array([[[1, -0.25], [-0.25, 0.5]], [[0.5, 0.25],[0.25, 0.5]], [[0.5, -0.25],[-0.25, 1]]])\n",
    "\n",
    "def sample_loc (prob, pi_distrbution):    \n",
    "    # return the idx loction of prob in the prob_distrbution\n",
    "    nr_loc = len(pi_distrbution)\n",
    "    cum_sum = np.cumsum(pi_distrbution)  \n",
    "    idx = np.where(prob < cum_sum)[0]  \n",
    "    return idx[0]\n",
    "\n",
    "\n",
    "N = 1000  # number of samples\n",
    "\n",
    "xs = np.zeros((N, 3))\n",
    "# simulator the trajectory \n",
    "for i in np.arange(0,N):   \n",
    "    \n",
    "    si_pi = np.random.uniform(0,1)\n",
    "    gs_id = sample_loc(si_pi, pi)   \n",
    "    ui = us[gs_id]\n",
    "    sgi = sgs[gs_id]   \n",
    "    xs[i,[0,1]] = np.random.multivariate_normal(ui, sgi)\n",
    "    xs[i,2] = gs_id\n",
    "\n",
    "\n",
    "x_g1 = xs[xs[:,2] == 0][:,[0,1]]\n",
    "x_g2 = xs[xs[:,2] == 1][:,[0,1]]\n",
    "x_g3 = xs[xs[:,2] == 2][:,[0,1]]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(x_g1[:,0], x_g1[:,1], c=colors[0], label='First') \n",
    "plt.scatter(x_g2[:,0], x_g2[:,1], c=colors[1], label='Second')\n",
    "plt.scatter(x_g3[:,0], x_g3[:,1], c=colors[2], label='Third') \n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.legend()\n",
    "plt.title('Simulated multivariate(K=3) normal distibutions ')\n",
    "plt.show() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_loggi(pi, ui, sigi, x, nr_x):\n",
    "    \n",
    "    sigi_inv = np.linalg.inv(sigi)\n",
    "    log2pi = np.log(2* math_pi)\n",
    "    log_sigi_det = np.log(np.linalg.det(sigi))\n",
    "    \n",
    "    diff = x - ui\n",
    "    exp_part = [- diff[j,:].dot(sigi_inv).dot(diff[j,:]) / 2 for j in np.arange(nr_x)]\n",
    "    loggi = np.log(pi) - (K * log2pi + log_sigi_det) / 2 + exp_part\n",
    "    \n",
    "    return loggi\n",
    "    \n",
    "    \n",
    "    \n",
    "def cal_gammas(K, ps, us, sigs, xs):\n",
    "    gamma_KNs = np.zeros((K,N))\n",
    "    \n",
    "    nr_x = N\n",
    "    logg_KN = np.zeros((K, N))\n",
    "    for j in np.arange(K):\n",
    "        logg_KN[j,:] = cal_loggi(ps[j], us[j], sigs[j], xs, nr_x)\n",
    "        \n",
    "    max_lgs = np.max(logg_KN, axis=0)      \n",
    "    lg_diff = logg_KN - max_lgs\n",
    "    sum_exp = np.sum(np.exp(lg_diff), axis=0)\n",
    "\n",
    "    for j in np.arange(K):                \n",
    "        gamma_KNs[j,:] = np.divide(np.exp(logg_KN[j,:] - max_lgs), sum_exp)\n",
    "    \n",
    "    return gamma_KNs\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_para(gammas, K, ps, us, sigs, xs):\n",
    "    \n",
    "    ps_new = ps.copy()\n",
    "    us_new = us.copy()\n",
    "    sigs_new = sigs.copy()\n",
    "    \n",
    "    for j in np.arange(K): \n",
    "        \n",
    "        sum_gamma = np.sum(gammas[j,:])\n",
    "        us_new[j,:] = np.sum(xs.T * gammas[j,:], axis=1) / sum_gamma      \n",
    "        ps_new[j] = sum_gamma / N    \n",
    "        diff = xs - us_new[j,:]   \n",
    "        sig_nom = [gammas[j,i] * np.outer(diff[i,:], diff[i,:]) for i in np.arange(N)]  \n",
    "        sigs_new[j,:] = np.sum(sig_nom, axis=0) / sum_gamma\n",
    "                   \n",
    "    return us_new, ps_new, sigs_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_loglik(K, ps, us, sigs, xs, gammas): \n",
    "    \n",
    "    loglik = 0\n",
    "    for k in range(K):\n",
    "        \n",
    "        sigi = sigs[k]\n",
    "        \n",
    "        sigi_inv = np.linalg.inv(sigi)\n",
    "        log2pi = np.log(2* math_pi)\n",
    "        log_sigi_det = np.log(np.linalg.det(sigi))\n",
    "        ui = us[k]\n",
    "        pi = ps[k]\n",
    "        diff = xs - ui \n",
    "        \n",
    "        \n",
    "        exp_part = [- diff[j,:].dot(sigi_inv).dot(diff[j,:]) / 2 for j in np.arange(N)]\n",
    "        log_part = - (K * log2pi + log_sigi_det) / 2 + exp_part  + np.log(pi)\n",
    "        \n",
    "        loglik += np.sum(gammas[k,:] * (log_part + exp_part))\n",
    "\n",
    "    return loglik\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_contour(ax, us, sigs, lcolors):\n",
    "    '''\n",
    "    This function plot on the axe ax ellipses (mu, sigma): reference to Henri Hours code for this plot\n",
    "    '''\n",
    "    for k in range(K):\n",
    "        v, w = np.linalg.eigh(sigs[k])\n",
    "        u = w[0] / np.linalg.norm(w[0])\n",
    "        angle = np.arctan2(u[1], u[0])\n",
    "        angle = 180 * angle / np.pi  # convert to degrees\n",
    "        v *= 8\n",
    "        ellipse = Ellipse(us[k], v[0], v[1], 180 + angle, lw=2, ec=lcolors[k], fc='none')\n",
    "        ellipse.set_clip_box(ax.bbox)\n",
    "        ellipse.set_alpha(0.5)\n",
    "        \n",
    "        ax.add_artist(ellipse)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xs_nl = xs[:,:2]  # not labeled data\n",
    "xs_mean = np.mean(xs_nl, axis=0)\n",
    "xs_cov = np.cov(xs_nl.T)\n",
    "\n",
    "\n",
    "\n",
    "# initilize the parameters: set them to be equal\n",
    "xs = xs_nl.copy()\n",
    "ps = np.ones((3,1)) / K\n",
    "\n",
    "us = np.array([[0, 0.5], [1, 1.2], [2,0.1]])\n",
    "#us = np.array([xs_mean, xs_mean, xs_mean])\n",
    "sigs = np.array([xs_cov, xs_cov, xs_cov])\n",
    "\n",
    "gammas = cal_gammas(K, ps, us, sigs, xs)\n",
    "    \n",
    "log_lik = cal_loglik(K, ps, us, sigs, xs, gammas)\n",
    "\n",
    "print (log_lik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#### 2. Implement the EM algorithm for GMMs\n",
    "\n",
    "xs_nl = xs[:,:2]  # not labeled data\n",
    "xs_mean = np.mean(xs_nl, axis=0)\n",
    "xs_cov = np.cov(xs_nl.T)\n",
    "\n",
    "# initilize the parameters: set them to be equal\n",
    "xs = xs_nl.copy()\n",
    "ps = np.ones((3,1)) / K\n",
    "\n",
    "us = np.array([[0, 0.5], [1, 1.2], [2,0.1]]) # random choose some centers\n",
    "sigs = np.array([xs_cov, xs_cov, xs_cov])\n",
    "\n",
    "\n",
    "\n",
    "Nr_iter = 500\n",
    "log_liks = np.zeros((Nr_iter, 1))\n",
    "\n",
    "for it in np.arange(Nr_iter): \n",
    "    \n",
    "    gammas = cal_gammas(K, ps, us, sigs, xs)\n",
    "    \n",
    "    log_lik = cal_loglik(K, ps, us, sigs, xs, gammas)\n",
    "    us_new, ps_new, sigs_new = update_para(gammas, K, ps, us, sigs, xs)\n",
    "    \n",
    "    log_liks[it] = log_lik\n",
    "    \n",
    "    title_str = \"Nr_Iter: \" + str(it) + \", Loglikelihood: \" + str(round(log_lik, 2))\n",
    "    \n",
    "    if it % 50 == 0: \n",
    "        #fig, ax = plt.subplots(figsize=(8,8))\n",
    "        fig, ax = plt.subplots()\n",
    "        plt.scatter(x_g1[:,0], x_g1[:,1], c='b', label='First') \n",
    "        plt.scatter(x_g2[:,0], x_g2[:,1], c='r', label='Second')\n",
    "        plt.scatter(x_g3[:,0], x_g3[:,1], c='k', label='Third') \n",
    "         \n",
    "        plot_contour(ax, us_new, sigs_new, colors)\n",
    "\n",
    "        ax.set_title(\"Iter: \" + str(it) + \", Loglikelihood: \" + str(np.round(log_lik, 2)))\n",
    "        plt.show()    \n",
    "        \n",
    "   \n",
    "    us = us_new.copy()\n",
    "    ps =  ps_new.copy()\n",
    "    sigs= sigs_new.copy()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evolution of log-likelihood\n",
    "plt.plot(np.arange(Nr_iter), log_liks)\n",
    "plt.title(\"Evolution of log-likelihood\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.arange(50), log_liks[:50])\n",
    "plt.title(\"Zoom In: show the first 50 iterations: Evolution of log-likelihood\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Test with different initial values: \n",
    "\n",
    "xs_nl = xs[:,:2]  # not labeled data\n",
    "xs_mean = np.mean(xs_nl, axis=0)\n",
    "xs_cov = np.cov(xs_nl.T)\n",
    "\n",
    "# initilize the parameters with the same values\n",
    "ps = np.ones((3,1)) / K\n",
    "us = np.array([xs_mean, xs_mean, xs_mean])\n",
    "sigs = np.array([xs_cov, xs_cov, xs_cov])\n",
    "\n",
    "Nr_iter = 500\n",
    "log_liks = np.zeros((Nr_iter, 1))\n",
    "\n",
    "for it in np.arange(Nr_iter): \n",
    "    \n",
    "    gammas = cal_gammas(K, ps, us, sigs, xs)\n",
    "    \n",
    "    log_lik = cal_loglik(K, ps, us, sigs, xs, gammas)\n",
    "    us_new, ps_new, sigs_new = update_para(gammas, K, ps, us, sigs, xs)\n",
    "    \n",
    "    log_liks[it] = log_lik\n",
    "    \n",
    "    title_str = \"Nr_Iter: \" + str(it) + \", Loglikelihood: \" + str(round(log_lik, 2))\n",
    "    \n",
    "    if it % 50 == 0: \n",
    "        #fig, ax = plt.subplots(figsize=(8,8))\n",
    "        fig, ax = plt.subplots()\n",
    "        plt.scatter(x_g1[:,0], x_g1[:,1], c='b', label='First') \n",
    "        plt.scatter(x_g2[:,0], x_g2[:,1], c='r', label='Second')\n",
    "        plt.scatter(x_g3[:,0], x_g3[:,1], c='k', label='Third') \n",
    "         \n",
    "        plot_contour(ax, us_new, sigs_new, colors)\n",
    "\n",
    "        ax.set_title(\"Iter: \" + str(it) + \", Loglikelihood: \" + str(np.round(log_lik, 2)))\n",
    "        plt.show()    \n",
    "          \n",
    "    us = us_new.copy()\n",
    "    ps =  ps_new.copy()\n",
    "    sigs= sigs_new.copy()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evolution of log-likelihood\n",
    "plt.plot(np.arange(Nr_iter), log_liks)\n",
    "plt.title(\"Evolution of log-likelihood\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.arange(50), log_liks[:50])\n",
    "plt.title(\"Zoom In: show the first 50 iterations: Evolution of log-likelihood\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclunsion: the model is very sensitive to the inital data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
