{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Probabilistic Graphical Models\n",
    "## Mini Project\n",
    "### Author: Xiang Yu, Email: shawnxiangyu@yahoo.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-negative matrix factorization (NMF or NNMF), also non-negative matrix approximation is a group of algorithms in multivariate analysis and linear algebra where a matrix V is factorized into (usually) two matrices W and H, with the property that all three matrices have no negative elements. (source: wiki)\n",
    "\n",
    "NMF is used for feature extraction and is generally seen to be useful when there are many attributes, particularly when the attributes are ambiguous or are not strong predictors. By combining attributes NMF can display patterns, topics, or themes which have importance. NMF method is found in many applications, for this project we apply NMF to the face images.\n",
    "\n",
    "\n",
    "#### Goal: Find $W, H$ such that for a given $V$, $ V \\approx W H$\n",
    "Given an $F \\times N$ matrix $V$ with nonnegative elements, we wish to\n",
    "find nonnegative, rank-$K$ matrices $W$ ($F \\times K$) and $H$ ($K\n",
    "\\times N$) such that $$ V \\approx W H $$\n",
    "\n",
    "or more precisely: \n",
    "$$ V_{fn} \\approx \\sum_{k = 1}^{K} W_{fk} H_{kn}$$\n",
    "\n",
    "The goal can be achieved by solving the following optimization problem: \n",
    "$$ (W, H) \\in  arg \\max_{W,\\  H \\geq 0} P(V; W, H) $$ \n",
    "\n",
    "#### E-step 1: E function overview\n",
    "\n",
    "In the following calculation, when no confusion occurs, we use $Z$ to denote the parameters $(W, H)$,i.e. $Z = WH$, then \n",
    "\n",
    "$$ P(V; W, H) = P(V; Z) = P(V|Z) $$\n",
    "\n",
    "We could solve the optimization problem with Expectationâ€“maximization(EM) algorithm taught during the lecture.\n",
    "\n",
    "Here we introduce a latent variable $S$ with the following properties: \n",
    "\n",
    "$$q(S) > 0,\\  \\sum_S q(S) = 1 $$\n",
    "\n",
    "Then the original optimization problem will be equivilant to \n",
    "$$ arg \\max_{W,\\  H \\geq 0} P(V; W, H)   \\propto  arg \\max_{Z \\geq 0} \\log P(V|Z)$$\n",
    "\n",
    "And \n",
    "\\begin{align}\n",
    "\\log P(V|Z)\n",
    "&=  \\log \\sum_S P(V, S|Z) \\\\\n",
    "& = \\log \\sum_S P(V, S|Z) \\frac{q(S)}{q(S)} \\\\\n",
    "& = \\log \\sum_S \\frac{P(V, S|Z)}{q(S)} q(S) \\\\\n",
    "& = \\log \\mathbb{E}[\\frac{P(V, S|Z)}{q(S)}]_{q(S)} \\\\\n",
    "& \\geq \\mathbb{E} \\log [\\frac{P(V, S|Z)}{q(S)}]_{q(S)} \n",
    "\\end{align}\n",
    "\n",
    "\n",
    "We have proved in the lecture for EM algorithm that: \n",
    "\n",
    "$$ q(S) = P(S|V, Z)$$\n",
    "\n",
    "\n",
    "\n",
    "Then we have \n",
    "\\begin{align}\n",
    "\\log P(V|Z) \\geq \\mathbb{E} \\log [\\frac{P(V, S|Z)}{q(S)}]_{q(S)} \n",
    "&  = \\sum q(S) \\log \\frac{P(V, S|Z)}{q(S)} \\\\\n",
    "&  = \\sum q(S) \\log {P(V, S|Z)} - \\sum q(S) \\log q(S) \\\\\n",
    "&  = \\mathbb{E} [\\log P(V, S|Z)]_{q(S)} - \\mathbb{E} [\\log q(S)]_{q(S)} \\\\\n",
    "&  = \\mathbb{E} [\\log P(V, S|Z)]_{P(S|V, Z^{t})} - \\mathbb{E} [\\log P(S|V, Z^{t})]_{P(S|V, Z^{t})}\n",
    "\\end{align} \n",
    "\n",
    "We need to maximize the right side of above equaiton with respect to the parameter $Z = (W, H)$.\n",
    "Then, \n",
    "\n",
    "$$\n",
    "arg \\max_{Z \\geq 0} \\mathbb{E} [\\log P(V, S|Z)]_{P(S|V, Z^{t})} - \\mathbb{E} [\\log P(S|V, Z^{t})]_{P(S|V, Z^{t})}  \\propto arg \\max_{Z \\geq 0} \\mathbb{E} [\\log P(V, S|Z)]_{P(S|V, Z^{t})}\n",
    "$$\n",
    "\n",
    "\n",
    "Then we have the E-step function to be maximized as follows: \n",
    "$$L(Z) = \\mathbb{E} [\\log P(V, S|Z)]_{P(S|V, Z^{t})}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to calculate $L(Z)$, we should calculate the terms in $L(Z)$ first. I.e. the following two terms: \n",
    "-  $P(S|V, Z^{t})$\n",
    "- $\\log P(V, S|Z)$\n",
    "\n",
    "#### E-step 2: term $P(S|V, Z^{t})$\n",
    "\n",
    "We have: \n",
    "$$P(S|V, Z^{t}) = \\frac{P(S, V, Z^{t})}{P(V, Z^{t}))} = \\frac{P(S, V|Z^{t})}{P(V|Z^{t})}$$\n",
    "\n",
    "And according to the directed graph model in Question 1.1, we have: \n",
    "\n",
    "$$P(S, V|Z^{t}) = P(V|S)P(S|Z^{t})$$\n",
    "\n",
    "Therefore, we have: \n",
    "$$P(S|V, Z^{t}) = \\frac{P(V|S)P(S|Z^{t})}{P(V|Z^{t})}$$\n",
    "\n",
    "\n",
    "Notice: the $S$ is introduced to have the following properties: \n",
    "\n",
    "$$V_{fn} = \\sum_{k = 1}^{K} S_{f\\_k\\_n}, \\  S_{f\\_k\\_n} \\sim \\operatorname{Poisson}(S_{f\\_k\\_n}; W_{fk} H_{kn}) $$\n",
    "\n",
    "When no confusion occurs, we write: \n",
    "$$S_{f\\_k\\_n}: = S_k, \\ and \\  W_{fk} H_{kn}: = Z_{f\\_k\\_n} := Z_k$$\n",
    "\n",
    "\n",
    "Thus: \n",
    "\n",
    "$$V_{fn} = \\sum_{k = 1}^{K} S_k, \\  S_k\\sim \\operatorname{Poisson}(S_k; Z_k) $$\n",
    "\n",
    "From Poission distribution we know that for any $a, b$, we have: \n",
    "$$\\operatorname{Poisson}(a; b) = P(a|b) = \\exp (a \\log b - b - \\log \\Gamma (a + 1)) $$\n",
    "\n",
    "\n",
    "Then: \n",
    "$$P(S_k|Z_k^{t}) = \\operatorname{Poisson}(S_k; Z_k^{t}) = \\exp (S_k \\log Z_k^{t} - Z_k^{t} - \\log \\Gamma (S_k + 1))  $$\n",
    "\n",
    "With $V_{fn} = \\sum_{k = 1}^{K} S_k$ and $S_k\\sim \\operatorname{Poisson}(S_k; Z_k) $, and according to the well-know superposition property of Poisson random variables. we have: \n",
    "\n",
    "\n",
    "$$P(V_{fn}|Z^{t}) \\sim \\operatorname{Poisson}(V_{fn}; \\sum_{k = 1}^{K}  Z_k^t)$$\n",
    "\n",
    "We also have: \n",
    "$$P(V_{fn}|S) = P(V_{fn}|S_{1:K}) = \\delta (V_{fn}- \\sum_{k = 1}^{K} S_k)$$\n",
    "where: \n",
    "$$\n",
    "\\delta(x) = \\{\n",
    "\\begin{array}{ll}\n",
    "  1, \\ if \\ x = 0 \\\\\n",
    "  0, \\ otherwise\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "With the given information and the lecture notes, we know that $P(S_{1:K}|V_{fn})$ follows a multinomial distribution, with \n",
    "\n",
    "$$P(S_{1:K}|V_{fn}) =\\delta (V_{fn}- \\sum_{k = 1}^{K} S_k) \\frac{V_{fn}!}{S_1!S_2!...S_K!}(\\frac{Z_1}{\\sum_k Z_k})^{S_1}...(\\frac{Z_K}{\\sum_k Z_k})^{S_K}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then: \n",
    "$$\\log P(S|V, Z^{t}) = \\log \\frac{P(V|S)P(S|Z^{t})}{P(V|Z^{t})} = \\log P(V|S)P(S|Z^{t}) - \\log P(V|Z^{t}) $$\n",
    "\n",
    "Where \n",
    "\\begin{align}\n",
    "\\log P(V|Z^{t})\n",
    "& = \\log \\Pi_{f,\\  n} \\operatorname{Poisson}(V_{fn}; \\sum_{k = 1}^{K}  Z_k^t) \\\\\n",
    "& = \\sum_{f,\\  n} \\log \\operatorname{Poisson}(V_{fn}; \\sum_{k = 1}^{K}  Z_k^t) \\\\\n",
    "&= \\sum_{f,\\  n} (V_{fn} \\log Z_k^{t} - Z_k^{t} - \\log \\Gamma (V_{fn} + 1)) \n",
    "\\end{align}\n",
    "\n",
    "and \n",
    "\\begin{align}\n",
    "\\log P(V|S)P(S|Z^{t})\n",
    "& = \\log \\Pi_{f,\\  n} [P(V_{fn}|S_{1:K}) \\Pi_{k = 1}^{K} P(S_k|Z^{t})] \\\\\n",
    "& = \\sum_{f,\\  n} [\\log \\delta (V_{fn}- \\sum_{k = 1}^{K} S_k) + \\sum_{k = 1}^{K} \\log \\operatorname{Poisson}(S_k; Z_k^{t})] \\\\\n",
    "&= \\sum_{f,\\  n} [\\log \\delta (V_{fn}- \\sum_{k = 1}^{K} S_k) + \\sum_{k = 1}^{K} (S_k \\log Z_k^{t} - Z_k^{t} - \\log \\Gamma (S_k + 1))]\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E-step 3: term $\\log P(V, S|Z)$\n",
    "As shown above, we have: \n",
    "\n",
    "$$\\log P(V, S|Z) = \\log P(V|S)P(S|Z)$$\n",
    "\n",
    "Then we have: \n",
    "\\begin{align}\n",
    "\\log P(V, S|Z) \n",
    "& = \\log P(V|S)P(S|Z) \\\\\n",
    "& = \\log \\Pi_{f,\\  n} [P(V_{fn}|S_{1:K}) \\Pi_{k = 1}^{K} P(S_k|Z)] \\\\\n",
    "& = \\sum_{f,\\  n} [\\log \\delta (V_{fn}- \\sum_{k = 1}^{K} S_k) + \\sum_{k = 1}^{K} \\log \\operatorname{Poisson}(S_k; Z_k)] \\\\\n",
    "&= \\sum_{f,\\  n} [\\log \\delta (V_{fn}- \\sum_{k = 1}^{K} S_k) + \\sum_{k = 1}^{K} (S_k \\log Z_k - Z_k - \\log \\Gamma (S_k + 1))]\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "#### E-step 4: E-function in detail: \n",
    "We have the expectation function as follows: \n",
    "$$L(Z) = \\mathbb{E} [\\log P(V, S|Z)]_{P(S|V, Z^{t})}$$\n",
    "\n",
    "Denote: $P(S|V, Z^{t}): = \\gamma^t$, then: \n",
    "\\begin{align}\n",
    "L(Z) \n",
    "& = \\mathbb{E} [\\log P(V, S|Z)]_{\\gamma^t} \\\\\n",
    "& = \\mathbb{E}(\\sum_{f,\\  n} [\\log \\delta (V_{fn}- \\sum_{k = 1}^{K} S_k) + \\sum_{k = 1}^{K} (S_k \\log Z_k - Z_k - \\log \\Gamma (S_k + 1))])_{\\gamma^t} \\\\\n",
    "& = \\sum_{f,\\  n} ( \\mathbb{E}[\\log \\delta (V_{fn}- \\sum_{k = 1}^{K} S_k)]_{\\gamma^t} + \\mathbb{E}[\\sum_{k = 1}^{K} (S_k \\log Z_k - Z_k - \\log \\Gamma (S_k + 1))]_{\\gamma^t}) \\\\\n",
    "& = Constant1 + \\sum_{f,\\  n}(\\mathbb{E}[\\sum_{k = 1}^{K} (S_k \\log Z_k - Z_k)]_{\\gamma^t} - \\mathbb{E}[ \\log \\Gamma (S_k + 1)]_{\\gamma^t}) \\\\\n",
    "& =  Constant1 + \\sum_{f,\\  n}\\mathbb{E}[\\sum_{k = 1}^{K} (S_k \\log Z_k - Z_k)]_{\\gamma^t} - Constant2\n",
    "\\end{align}\n",
    "\n",
    "Here, with $ Z^{t}$ given, the two terms: $\\mathbb{E}[\\log \\delta (V_{fn}- \\sum_{k = 1}^{K} S_k)]_{\\gamma^t} := Constant1$ and $\\mathbb{E}[ \\log \\Gamma (S_k + 1)]_{\\gamma^t}:=Constant2$ will be constant when the expectation is calculated with respect to $\\gamma^t$ .\n",
    "\n",
    "Since the M-step is to maximize $L(Z)$, then\n",
    "\n",
    "$$Z^{t+1} = \\arg \\max_{Z \\geq 0} L(Z) \\propto  arg \\max_{Z \\geq 0} \\sum_{f,\\  n}\\mathbb{E}[\\sum_{k = 1}^{K} (S_k \\log Z_k - Z_k)]_{\\gamma^t}$$\n",
    "\n",
    "Therefore, we could update the objective function $L(Z)$ as follows: \n",
    "\\begin{align}\n",
    "L(Z) \n",
    "& = \\sum_{f,\\  n}\\mathbb{E}[\\sum_{k = 1}^{K} (S_k \\log Z_k - Z_k)]_{\\gamma^t} \\\\\n",
    "& = \\sum_{f,\\  n}(\\mathbb{E}[\\sum_{k = 1}^{K} (S_k \\log Z_k]_{\\gamma^t} - \\mathbb{E}[Z_k]_{\\gamma^t})\\\\\n",
    "& = \\sum_{f,\\  n}(\\sum_{k = 1}^{K} (\\gamma^t S_k \\log Z_k - Z_k)\n",
    "\\end{align}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### M-step 1:  objective function in the form of $W, H$\n",
    "We know that the optimal solution $Z^*$ of $\\max_{Z \\geq 0} L(Z)$ is the stationary point of $L(Z)$,i.e. \n",
    "$$\\bigtriangledown L(Z^*) = 0$$\n",
    "\n",
    "We know that $Z = WH, Z_k = Z_{f\\_k\\_n}  = W_{fk} H_{kn}$, we would like to find out the update rule for $W, H$ seperately. \n",
    "\n",
    "We write $L(Z)$ and all the terms within here: \n",
    "$$L(Z) = \\sum_{f,\\  n}(\\sum_{k = 1}^{K} (\\gamma^t S_k \\log Z_k - Z_k)$$\n",
    "We have $\\gamma^t = P(S|V, Z^{t}) $ and \n",
    "\\begin{align}\n",
    "\\log \\gamma^t \n",
    "& = \\log P(S|V, Z^{t}) \\\\\n",
    "& = \\log P(V|S)P(S|Z^{t}) - \\log P(V|Z^{t}) \\\\\n",
    "& = \\sum_{f,\\  n} [\\log \\delta (V_{fn}- \\sum_{k = 1}^{K} S_k) + \\sum_{k = 1}^{K} (S_k \\log Z_k^{t} - Z_k^{t} - \\log \\Gamma (S_k + 1))] - \\sum_{f,\\  n} (V_{fn} \\log Z_k^{t} - Z_k^{t} - \\log \\Gamma (V_{fn} + 1)) \n",
    "\\end{align}\n",
    "\n",
    "\n",
    "We have \n",
    "$$V_{fn} = \\sum_{k = 1}^{K} S_{f\\_k\\_n}, \\  S_{f\\_k\\_n} \\sim \\operatorname{Poisson}(S_{f\\_k\\_n}; W_{fk} H_{kn}) $$\n",
    "We could simplify the term with $\\gamma^t S_k$ here based on the properties of mutilnomial and Possion distribution:  \n",
    "$$\\gamma^t S_k = \\mathbb{E}[S_k]_{\\gamma^t} = V_{fn}P(S_k) = V_{fn} \\frac{Z_k^t}{\\sum_{k=1}^K Z_k^t} = V_{fn} \\frac{W_{fk}^t H_{kn}^t}{\\sum_{k=1}^K W_{fk}^t H_{kn}^t}$$\n",
    "\n",
    "\n",
    "Then $L(Z)$ to be expressed with $W, H$ will be as follows: \n",
    "\n",
    "$$L(WH) = \\sum_{f,\\  n}(\\sum_{k = 1}^{K} (V_{fn} \\frac{W_{fk}^t H_{kn}^t}{\\sum_{k=1}^K W_{fk}^t H_{kn}^t} \\log (W_{fk} H_{kn}) - W_{fk} H_{kn})$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### M-step 2:  update rule of $W, H$\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial L}{\\partial W_{fk}} \n",
    "& = \\frac{\\partial }{\\partial W_{fk}} \\sum_f \\sum_n (\\sum_{k = 1}^{K} \\gamma^t S_k  \\log (W_{fk} H_{kn}) - W_{fk} H_{kn}) \\\\\n",
    "& = \\sum_n(\\frac{\\gamma^t S_k}{W_{fk}} - H_{kn}) \\\\\n",
    "& = - \\sum_nH_{kn} +  \\frac{\\sum_n\\gamma^t S_k}{W_{fk}} \\\\\n",
    "& = - \\sum_nH_{kn} +  \\frac{\\sum_n(V_{fn} \\frac{W_{fk}^t H_{kn}^t}{\\sum_{k=1}^K W_{fk}^t H_{kn}^t})}{W_{fk}}\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "Then, \n",
    "\\begin{align}\n",
    "W_{fk}^{t+1} \n",
    "& = \\frac{\\sum_n\\gamma^t S_k}{\\sum_nH_{kn}} \\\\\n",
    "& = \\frac{\\sum_nV_{fn} \\frac{W_{fk}^t H_{kn}^t}{\\sum_{k=1}^K W_{fk}^t H_{kn}^t}}{\\sum_nH_{kn}} \\\\\n",
    "& =  \\frac{W_{fk}^t \\sum_n\\frac{V_{fn}H_{kn}^t}{\\sum_{k=1}^K W_{fk}^t H_{kn}^t}}{\\sum_nH_{kn}}\n",
    "\\end{align}\n",
    "\n",
    "The calculaltion for $H_{kn}$ is quite similar, and we could get the update rule for $H_{kn}$ as follows: \n",
    "$$H_{kn}^{t+1} = \\frac{H_{kn}^t \\sum_f\\frac{W_{fk}^tV_{fn}}{\\sum_{k=1}^K W_{fk}^t H_{kn}^t}}{\\sum_fW_{fk}^t}$$\n",
    "\n",
    "Finally, we have find the EM algorithm/formula for NMF problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 2. Implement the EM algorithm for GMMs\n",
    "\n",
    "xs_nl = xs[:,:2]  # not labeled data\n",
    "xs_mean = np.mean(xs_nl, axis=0)\n",
    "xs_cov = np.cov(xs_nl.T)\n",
    "\n",
    "# initilize the parameters: set them to be equal\n",
    "xs = xs_nl.copy()\n",
    "ps = np.ones((3,1)) / K\n",
    "\n",
    "us = np.array([[0, 0.5], [1, 1.2], [2,0.1]]) # random choose some centers\n",
    "sigs = np.array([xs_cov, xs_cov, xs_cov])\n",
    "\n",
    "\n",
    "\n",
    "Nr_iter = 500\n",
    "log_liks = np.zeros((Nr_iter, 1))\n",
    "\n",
    "for it in np.arange(Nr_iter): \n",
    "    \n",
    "    gammas = cal_gammas(K, ps, us, sigs, xs)\n",
    "    \n",
    "    log_lik = cal_loglik(K, ps, us, sigs, xs, gammas)\n",
    "    us_new, ps_new, sigs_new = update_para(gammas, K, ps, us, sigs, xs)\n",
    "    \n",
    "    log_liks[it] = log_lik\n",
    "    \n",
    "    title_str = \"Nr_Iter: \" + str(it) + \", Loglikelihood: \" + str(round(log_lik, 2))\n",
    "    \n",
    "    if it % 50 == 0: \n",
    "        #fig, ax = plt.subplots(figsize=(8,8))\n",
    "        fig, ax = plt.subplots()\n",
    "        plt.scatter(x_g1[:,0], x_g1[:,1], c='b', label='First') \n",
    "        plt.scatter(x_g2[:,0], x_g2[:,1], c='r', label='Second')\n",
    "        plt.scatter(x_g3[:,0], x_g3[:,1], c='k', label='Third') \n",
    "         \n",
    "        plot_contour(ax, us_new, sigs_new, colors)\n",
    "\n",
    "        ax.set_title(\"Iter: \" + str(it) + \", Loglikelihood: \" + str(np.round(log_lik, 2)))\n",
    "        plt.show()    \n",
    "        \n",
    "   \n",
    "    us = us_new.copy()\n",
    "    ps =  ps_new.copy()\n",
    "    sigs= sigs_new.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\\begin{align}\n",
    "\\large \\log P(V|Z) \\geq \\mathbb{E} \\log [\\frac{P(V, S|Z)}{q(S)}]_{q(S)} \n",
    "& \\large = \\sum q(S) \\log \\frac{P(V, S|Z)}{q(S)} \\\\\n",
    "& \\large = \\sum q(S) \\log {P(V, S|Z)} - \\sum q(S) \\log q(S) \\\\\n",
    "& \\large = \\mathbb{E} [\\log P(V, S|Z)]_{q(S)} - \\mathbb{E} [\\log q(S)]_{q(S)} \\\\\n",
    "& \\large = \\mathbb{E} [\\log P(V, S|Z)]_{P(S|V, Z^{t})} - \\mathbb{E} [\\log P(S|V, Z^{t})]_{P(S|V, Z^{t})}\n",
    "\\end{align} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Denote: $P(S|V, Z^{t}): = \\gamma^t$, then: \n",
    "\\begin{align}\n",
    "L(Z) \n",
    "& = \\mathbb{E} [\\log P(V, S|Z)]_{\\gamma^t} \\\\\n",
    "& = \\mathbb{E}(\\sum_{f,\\  n} [\\log \\delta (V_{fn}- \\sum_{k = 1}^{K} S_k) + \\sum_{k = 1}^{K} (S_k \\log Z_k - Z_k - \\log \\Gamma (S_k + 1))])_{\\gamma^t} \\\\\n",
    "& = \\sum_{f,\\  n} ( \\mathbb{E}[\\log \\delta (V_{fn}- \\sum_{k = 1}^{K} S_k)]_{\\gamma^t} + \\mathbb{E}[\\sum_{k = 1}^{K} (S_k \\log Z_k - Z_k - \\log \\Gamma (S_k + 1))]_{\\gamma^t}) \\\\\n",
    "& = Constant1 + \\sum_{f,\\  n}(\\mathbb{E}[\\sum_{k = 1}^{K} (S_k \\log Z_k - Z_k)]_{\\gamma^t} - \\mathbb{E}[ \\log \\Gamma (S_k + 1)]_{\\gamma^t}) \\\\\n",
    "& =  Constant1 + \\sum_{f,\\  n}\\mathbb{E}[\\sum_{k = 1}^{K} (S_k \\log Z_k - Z_k)]_{\\gamma^t} - Constant2\n",
    "\\end{align}\n",
    "\n",
    "Here, with $ Z^{t}$ given, the two terms: $\\mathbb{E}[\\log \\delta (V_{fn}- \\sum_{k = 1}^{K} S_k)]_{\\gamma^t} := Constant1$ and $\\mathbb{E}[ \\log \\Gamma (S_k + 1)]_{\\gamma^t}:=Constant2$ will be constant when the expectation is calculated with respect to $\\gamma^t$ .\n",
    "\n",
    "Since the M-step is to maximize $L(Z)$, then\n",
    "\n",
    "$$Z^{t+1} = \\arg \\max_{Z \\geq 0} L(Z) \\propto  arg \\max_{Z \\geq 0} \\sum_{f,\\  n}\\mathbb{E}[\\sum_{k = 1}^{K} (S_k \\log Z_k - Z_k)]_{\\gamma^t}$$\n",
    "\n",
    "Therefore, we could update the objective function $L(Z)$ as follows: \n",
    "\\begin{align}\n",
    "L(Z) \n",
    "& = \\sum_{f,\\  n}\\mathbb{E}[\\sum_{k = 1}^{K} (S_k \\log Z_k - Z_k)]_{\\gamma^t} \\\\\n",
    "& = \\sum_{f,\\  n}(\\mathbb{E}[\\sum_{k = 1}^{K} (S_k \\log Z_k]_{\\gamma^t} - \\mathbb{E}[Z_k]_{\\gamma^t})\\\\\n",
    "& = \\sum_{f,\\  n}(\\sum_{k = 1}^{K} (S_k \\log Z_k^{t}\\gamma^t - Z_k^{t})\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$$ V_{fn} \\sim \\operatorname{Poisson}(V_{fn}; \\sum_{k = 1}^{K}  Z_k)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " = \\frac{P(V|S)P(S|Z^{t})}{\\sum_S P(V|S)P(S|Z^{t})} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$$\n",
    "\\delta(t) = \\Big\\{ \\frac34 \\Bigg.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "$$P(V|S)P(S|Z^{t}) = \\Pi_{f,\\  n} P(V_{fn}|S)P(S|Z^{t})$$\n",
    "\n",
    "= \\delta (V_{fn}- \\sum_{k = 1}^{K} S_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\\begin{align}\n",
    "P(S|V, Z^{t})\n",
    "&=  \\frac{P(S, V|Z^{t})}{P(V|Z^{t}))} \\\\\n",
    "& = \\log \\sum_S P(V, S|Z) \\frac{q(S)}{q(S)} \\\\\n",
    "\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "& = \\mathbb{E} \\log [\\frac{P(V, S|Z)}{q(S)}]_{q(S)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "& = \\log \\E\\[\\frac{P(V, S|Z)}{P(S)}\\]_{P(S)} \\\\\n",
    "& = \\E\\[\\log \\frac{P(V, S|Z)}{P(S)}\\]_{P(S)\n",
    "P(V|Z) \\frac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\\begin{align}\n",
    "\\large \\log(\\sum\\pi_j\\mathcal{N_j}) \n",
    " &= \\large log\\sum_{i=1}^I \\pi_j \\kappa_j\\exp(v_j) \\\\\n",
    " & = \\large \\log\\sum_{j=1}^I \\pi_j\\kappa_j \\exp(v_j- V_{max} + V_{max}) \\\\\n",
    "  & = \\large \\log\\sum_{j=1}^I \\pi_j\\kappa_j\\exp(v_j- V_{max}) \\exp(V_{max}) \\\\\n",
    " & = \\large V_{max} + \\log\\sum_{j=1}^I \\pi_j\\kappa_j\\exp(v_j- V_{max})\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "So our goal is to find $W, H$ such that for a given $V$\n",
    "$$Err(W,H) = \\min_{W,H}\\|V-WH\\|\\,,$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
